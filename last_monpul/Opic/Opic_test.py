from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
from fastapi.encoders import jsonable_encoder
import whisper
import requests
import json
import tempfile
import os
from typing import Dict, Any, List, Optional
import logging
from datetime import datetime
from pydantic import BaseModel
from bson import ObjectId

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Enhanced OPIc Test API",
    description="AI ê¸°ë°˜ ì˜ì–´ ë§í•˜ê¸° í‰ê°€ ì‹œìŠ¤í…œ - MongoDB ì—°ë™",
    version="2.0.0"
)

# CORS ì„¤ì • ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000", "*"],  # í”„ë¡ íŠ¸ì—”ë“œ ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MongoDB ì„¤ì •
MONGODB_URL = "mongodb://localhost:27017"
DATABASE_NAME = "opic_test"
client = None
database = None

# Whisper ëª¨ë¸ ë¡œë“œ
logger.info("Whisper ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
try:
    whisper_model = whisper.load_model("medium")
    logger.info("âœ… Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    logger.error(f"âŒ Whisper ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    whisper_model = None

# Groq ì„¤ì •
from groq import Groq

GROQ_API_KEY = ""
GROQ_MODEL = "llama-3.3-70b-versatile"

try:
    groq_client = Groq(api_key=GROQ_API_KEY)
    logger.info("âœ… Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    logger.error(f"âŒ Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    groq_client = None


# Pydantic ëª¨ë¸ë“¤
class Question(BaseModel):
    id: Optional[str] = None
    topic: str
    question_text: str
    difficulty: str  # beginner, intermediate, advanced


class TextSubmission(BaseModel):
    question_id: str
    user_text: str
    mode: str  # "practice" or "exam"


class ExamSession(BaseModel):
    topic: str
    question_count: int
    mode: str = "exam"


class EvaluationResult(BaseModel):
    question_id: str
    question_text: str
    user_answer: str
    transcription: Optional[str] = None
    grade: str
    score: int
    problem_understanding: Dict[str, Any]
    answer_structure: Dict[str, Any]
    content_expression: Dict[str, Any]
    topic_delivery: Dict[str, Any]
    overall_feedback: str
    timestamp: str


async def connect_to_mongodb():
    """MongoDB ì—°ê²° í•¨ìˆ˜"""
    global client, database
    try:
        client = AsyncIOMotorClient(MONGODB_URL)
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        await client.admin.command('ping')
        database = client[DATABASE_NAME]
        logger.info("âœ… MongoDB ì—°ê²° ì„±ê³µ")
        return True
    except Exception as e:
        logger.error(f"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {e}")
        return False


# ì•± ì‹œì‘ ì´ë²¤íŠ¸
@app.on_event("startup")
async def startup_event():
    logger.info("=== ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ===")
    success = await connect_to_mongodb()
    if not success:
        logger.error("MongoDB ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


@app.on_event("shutdown")
async def shutdown_event():
    global client
    if client:
        client.close()
        logger.info("MongoDB ì—°ê²°ì„ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")


class OpicEvaluator:
    """OPIc ë‹µë³€ í‰ê°€ í´ë˜ìŠ¤ - ì—„ê²©í•œ í‰ê°€ ê¸°ì¤€ ì ìš©"""

    def create_evaluation_prompt(self, question: str, user_answer: str) -> str:
        """í‰ê°€ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = f"""You are a strict expert English speaking test evaluator for OPIc (Oral Proficiency Interview - computer). 
Please evaluate the following English response based on these detailed criteria:

1. Problem Understanding (ë¬¸ì œ ì´í•´ë ¥)
   - Topic Relevance: How well does the answer match the question topic?
   - Expression Accuracy: Correctness of vocabulary and grammar
   - Meaning Clarity: Clear delivery of intent and information

2. Answer Structure (ë‹µë³€ êµ¬ì„±ë ¥)
   - Sentence Formation: Grammar and sentence structure completeness
   - Tense Consistency: Appropriate use of tenses
   - Vocabulary Range: Variety and appropriateness of words used
   - Word Repetition: Minimizing same word repetition

3. Content Expression (ë‚´ìš© í‘œí˜„ë ¥)
   - Modifier Details: Use of adverbs/adjectives and detailed descriptions
   - Connector Variety: Ability to connect sentences with various conjunctions
   - Situational Appropriateness: Suitable response to the question context

4. Topic Delivery (ì£¼ì œ ì „ë‹¬ë ¥)
   - Speech Volume: Speaking pace and volume
   - Speaking Speed: Natural flow of speech
   - Response Continuity: Ability to sustain answer in one go
   - Response Length: Appropriate length and content volume

STRICT SCORING GUIDELINES:
- Score 90-100: Near-native fluency, complex grammar, rich vocabulary, excellent structure
- Score 80-89: Advanced level, minor errors, good variety, well-organized
- Score 70-79: Intermediate-high, some errors, adequate vocabulary, decent structure  
- Score 60-69: Intermediate, noticeable errors, basic vocabulary, simple structure
- Score 50-59: Low-intermediate, frequent errors, limited vocabulary
- Score 40-49: Beginner-high, many errors, very basic vocabulary
- Score 30-39: Beginner, severe errors, minimal vocabulary
- Score 0-29: Unable to communicate effectively

Question: "{question}"
User's Answer: "{user_answer}"

Please provide your evaluation in the following JSON format:
{{
    "grade": "1-5 (overall grade)",
    "score": "0-100 overall numeric score",
    "problem_understanding": {{
        "score": "0-25 points",
        "feedback": "Korean feedback for ë¬¸ì œ ì´í•´ë ¥ (ì£¼ì œ ì¼ì¹˜ë„, í‘œí˜„ ì •í™•ì„±, ì˜ë¯¸ ì „ë‹¬ì„±)"
    }},
    "answer_structure": {{
        "score": "0-25 points", 
        "feedback": "Korean feedback for ë‹µë³€ êµ¬ì„±ë ¥ (ë¬¸ì¥ í˜•ì‹, ì‹œì œ ì¼ì¹˜, ì–´íœ˜ë ¥, ë‹¨ì–´ ì¤‘ë³µë„)"
    }},
    "content_expression": {{
        "score": "0-25 points",
        "feedback": "Korean feedback for ë‚´ìš© í‘œí˜„ë ¥ (ìˆ˜ì‹ì–´ ìƒì„¸ì„±, ì ‘ì†ì–´ ë‹¤ì–‘ì„±, ìƒí™© ëŒ€ì‘ë ¥)"
    }},
    "topic_delivery": {{
        "score": "0-25 points",
        "feedback": "Korean feedback for ì£¼ì œ ì „ë‹¬ë ¥ (ë°œí™” ì„±ëŸ‰, ë§í•˜ê¸° ì†ë„, ë‹µë³€ ì§€ì†ì„±, ë‹µë³€ ê¸¸ì´)"
    }},
    "overall_feedback": "Korean overall feedback and improvement suggestions"
}}

Be very strict with scoring. Most answers should fall in the 40-70 range unless truly exceptional."""
        return prompt

    def query_groq_api(self, prompt: str) -> Dict[str, Any]:
        """Groq APIì— ì§ì ‘ POST ìš”ì²­"""
        try:
            url = "https://api.groq.com/openai/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {GROQ_API_KEY}",
                "Content-Type": "application/json"
            }
            data = {
                "model": GROQ_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 800,
                "temperature": 0.3  # ë” ì¼ê´€ëœ í‰ê°€ë¥¼ ìœ„í•´ ë‚®ì¶¤
            }

            response = requests.post(url, headers=headers, json=data)
            if response.status_code != 200:
                logger.error(f"Groq API ì˜¤ë¥˜ ì‘ë‹µ: {response.text}")
                return {"error": f"API request failed: {response.text}"}

            result = response.json()
            message_content = result["choices"][0]["message"]["content"]
            return {"generated_text": message_content}

        except Exception as e:
            logger.error(f"Groq API ìš”ì²­ ì˜¤ë¥˜: {e}")
            return {"error": f"API request failed: {str(e)}"}

    def parse_evaluation_result(self, api_response: str) -> Dict[str, Any]:
        """API ì‘ë‹µì—ì„œ í‰ê°€ ê²°ê³¼ íŒŒì‹±"""
        try:
            start_idx = api_response.find('{')
            end_idx = api_response.rfind('}') + 1

            if start_idx != -1 and end_idx > start_idx:
                json_str = api_response[start_idx:end_idx]
                evaluation = json.loads(json_str)

                grade = str(evaluation.get("grade", "2"))

                # ê° ê¸°ì¤€ë³„ ì ìˆ˜ ì¶”ì¶œ
                problem_understanding = evaluation.get("problem_understanding", {})
                answer_structure = evaluation.get("answer_structure", {})
                content_expression = evaluation.get("content_expression", {})
                topic_delivery = evaluation.get("topic_delivery", {})

                # ì´ì  ê³„ì‚° (ê° í•­ëª© 25ì ì”©)
                total_score = (
                        int(problem_understanding.get("score", 10)) +
                        int(answer_structure.get("score", 10)) +
                        int(content_expression.get("score", 10)) +
                        int(topic_delivery.get("score", 10))
                )

                return {
                    "grade": grade,
                    "score": max(0, min(100, total_score)),
                    "problem_understanding": problem_understanding,
                    "answer_structure": answer_structure,
                    "content_expression": content_expression,
                    "topic_delivery": topic_delivery,
                    "overall_feedback": evaluation.get("overall_feedback", "í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                }
            else:
                raise ValueError("JSON format not found in response")

        except (json.JSONDecodeError, ValueError, KeyError) as e:
            logger.error(f"ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return self.generate_fallback_evaluation(api_response)

    def generate_fallback_evaluation(self, user_answer: str) -> Dict[str, Any]:
        """API íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì—„ê²©í•œ ê¸°ë³¸ í‰ê°€ ê²°ê³¼ ìƒì„±"""
        word_count = len(user_answer.split())
        sentence_count = len([s for s in user_answer.split('.') if s.strip()])

        # ë¬¸ë²• ì˜¤ë¥˜ ê°„ë‹¨ ì²´í¬
        grammar_issues = []
        if ' i ' in user_answer.lower() or user_answer.startswith('i '):
            grammar_issues.append("ëŒ€ë¬¸ì I ì‚¬ìš©")
        if user_answer.count('a') + user_answer.count('an') + user_answer.count('the') < word_count * 0.1:
            grammar_issues.append("ê´€ì‚¬ ì‚¬ìš© ë¶€ì¡±")

        # ê° ê¸°ì¤€ë³„ ì ìˆ˜ ê³„ì‚° (25ì ì”©)
        if word_count >= 80 and sentence_count >= 6:
            scores = {
                "problem_understanding": 18,
                "answer_structure": 17,
                "content_expression": 16,
                "topic_delivery": 19
            }
            grade = "4"
        elif word_count >= 50 and sentence_count >= 4:
            scores = {
                "problem_understanding": 15,
                "answer_structure": 14,
                "content_expression": 13,
                "topic_delivery": 16
            }
            grade = "3"
        elif word_count >= 30 and sentence_count >= 3:
            scores = {
                "problem_understanding": 12,
                "answer_structure": 10,
                "content_expression": 11,
                "topic_delivery": 12
            }
            grade = "2"
        elif word_count >= 10:
            scores = {
                "problem_understanding": 8,
                "answer_structure": 7,
                "content_expression": 8,
                "topic_delivery": 9
            }
            grade = "1"
        else:
            scores = {
                "problem_understanding": 5,
                "answer_structure": 4,
                "content_expression": 5,
                "topic_delivery": 6
            }
            grade = "1"

        total_score = sum(scores.values())

        return {
            "grade": grade,
            "score": total_score,
            "problem_understanding": {
                "score": scores["problem_understanding"],
                "feedback": f"ì§ˆë¬¸ ì´í•´ë„: {'ìƒ' if scores['problem_understanding'] >= 15 else 'ì¤‘' if scores['problem_understanding'] >= 10 else 'í•˜'}. ì£¼ì œì™€ì˜ ì—°ê´€ì„±ê³¼ í•µì‹¬ ë‚´ìš© íŒŒì•… ëŠ¥ë ¥ì„ í–¥ìƒì‹œì¼œì•¼ í•©ë‹ˆë‹¤."
            },
            "answer_structure": {
                "score": scores["answer_structure"],
                "feedback": f"ë¬¸ë²• ì •í™•ë„: {'ìƒ' if scores['answer_structure'] >= 15 else 'ì¤‘' if scores['answer_structure'] >= 10 else 'í•˜'}. ë¬¸ì¥ êµ¬ì¡°ì™€ ì‹œì œ ì‚¬ìš©, ì–´íœ˜ ë‹¤ì–‘ì„±ì—ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
            },
            "content_expression": {
                "score": scores["content_expression"],
                "feedback": f"í‘œí˜„ë ¥: {'ìƒ' if scores['content_expression'] >= 15 else 'ì¤‘' if scores['content_expression'] >= 10 else 'í•˜'}. ìˆ˜ì‹ì–´ì™€ ì ‘ì†ì–´ë¥¼ í™œìš©í•œ í’ë¶€í•œ í‘œí˜„ ì—°ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤."
            },
            "topic_delivery": {
                "score": scores["topic_delivery"],
                "feedback": f"ì „ë‹¬ë ¥: {'ìƒ' if scores['topic_delivery'] >= 15 else 'ì¤‘' if scores['topic_delivery'] >= 10 else 'í•˜'}. ë‹µë³€ ê¸¸ì´ì™€ ë‚´ìš©ì˜ ì§€ì†ì„±ì„ ê°œì„ í•´ì•¼ í•©ë‹ˆë‹¤."
            },
            "overall_feedback": f"ì´ {total_score}ì ì…ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ {'ì¤‘ê¸‰' if total_score >= 60 else 'ì´ˆê¸‰'} ìˆ˜ì¤€ìœ¼ë¡œ í‰ê°€ë˜ë©°, íŠ¹íˆ {'ë¬¸ë²• ì •í™•ì„±' if min(scores.values()) == scores['answer_structure'] else 'í‘œí˜„ë ¥' if min(scores.values()) == scores['content_expression'] else 'ë¬¸ì œ ì´í•´ë ¥'}ì— ì§‘ì¤‘ì ì¸ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤."
        }

    async def evaluate_response(self, question: str, user_answer: str) -> Dict[str, Any]:
        """ì „ì²´ í‰ê°€ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        logger.info(f"ë‹µë³€ í‰ê°€ ì‹œì‘: {user_answer[:50]}...")

        prompt = self.create_evaluation_prompt(question, user_answer)
        api_result = self.query_groq_api(prompt)

        if "error" in api_result:
            logger.error(f"API í˜¸ì¶œ ì˜¤ë¥˜: {api_result['error']}")
            return self.generate_fallback_evaluation(user_answer)

        generated_text = api_result.get("generated_text", "")
        evaluation = self.parse_evaluation_result(generated_text)

        logger.info(f"í‰ê°€ ì™„ë£Œ - ì ìˆ˜: {evaluation['score']}, ë“±ê¸‰: {evaluation['grade']}")
        return evaluation


# ì „ì—­ í‰ê°€ì ì¸ìŠ¤í„´ìŠ¤
evaluator = OpicEvaluator()


# API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "Enhanced OPIc Test API is running",
        "version": "2.0.0",
        "features": ["Audio & Text Submission", "Practice & Exam Mode", "MongoDB Integration", "Detailed Evaluation"],
        "timestamp": datetime.now().isoformat()
    }


@app.get("/topics")
async def get_topics():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ì£¼ì œ ë°˜í™˜"""
    global database

    if database is None:
        if not await connect_to_mongodb():
            raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    try:
        pipeline = [
            {"$group": {"_id": "$topic", "count": {"$sum": 1}}},
            {"$sort": {"_id": 1}}
        ]
        topics = await database.questions.aggregate(pipeline).to_list(length=None)
        result = [{"topic": topic["_id"], "question_count": topic["count"]} for topic in topics]

        logger.info(f"ì£¼ì œ ì¡°íšŒ ì„±ê³µ: {len(result)}ê°œ ì£¼ì œ")
        return result

    except Exception as e:
        logger.error(f"ì£¼ì œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì£¼ì œë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.get("/questions/{topic}")
async def get_questions_by_topic(topic: str, difficulty: Optional[str] = None, limit: Optional[int] = None):
    """ì£¼ì œë³„ ì§ˆë¬¸ ì¡°íšŒ"""
    global database

    if database is None:
        if not await connect_to_mongodb():
            raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    try:
        filter_query = {"topic": topic}
        if difficulty:
            filter_query["difficulty"] = difficulty

        cursor = database.questions.find(filter_query)
        if limit:
            cursor = cursor.limit(limit)

        questions = await cursor.to_list(length=None)

        if not questions:
            logger.warning(f"ì£¼ì œ '{topic}'ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            raise HTTPException(status_code=404, detail=f"ì£¼ì œ '{topic}'ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ObjectIdë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        for question in questions:
            question["id"] = str(question["_id"])
            del question["_id"]

        logger.info(f"'{topic}' ì£¼ì œì˜ ì§ˆë¬¸ {len(questions)}ê°œ ì¡°íšŒ ì„±ê³µ")
        return questions

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì§ˆë¬¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì§ˆë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.post("/exam-session")
async def create_exam_session(session: ExamSession):
    """ì‹œí—˜ ì„¸ì…˜ ìƒì„± - ì£¼ì œë³„ ë¬¸ì œ ì„ íƒ"""
    global database

    if database is None:
        if not await connect_to_mongodb():
            raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    try:
        questions = await database.questions.find(
            {"topic": session.topic}
        ).limit(session.question_count).to_list(length=None)

        if len(questions) < session.question_count:
            raise HTTPException(
                status_code=400,
                detail=f"ìš”ì²­í•œ ë¬¸ì œ ìˆ˜({session.question_count})ë³´ë‹¤ ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì œê°€ ì ìŠµë‹ˆë‹¤. (ì‚¬ìš© ê°€ëŠ¥: {len(questions)})"
            )

        # ì„¸ì…˜ ì •ë³´ ì €ì¥
        session_data = {
            "topic": session.topic,
            "question_count": session.question_count,
            "questions": [str(q["_id"]) for q in questions],
            "created_at": datetime.now(),
            "status": "active"
        }

        session_result = await database.exam_sessions.insert_one(session_data)
        session_id = str(session_result.inserted_id)

        # ì§ˆë¬¸ë“¤ì˜ ObjectIdë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        for question in questions:
            question["id"] = str(question["_id"])
            del question["_id"]

        logger.info(f"ì‹œí—˜ ì„¸ì…˜ ìƒì„± ì„±ê³µ: {session_id}")
        return {
            "session_id": session_id,
            "questions": questions,
            "topic": session.topic
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì‹œí—˜ ì„¸ì…˜ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì‹œí—˜ ì„¸ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.options("/evaluate-audio")
async def options_evaluate_audio():
    """CORS preflight ìš”ì²­ ì²˜ë¦¬"""
    return {"message": "OK"}


@app.post("/evaluate-audio")
async def evaluate_audio_response(
        audio: UploadFile = File(...),
        question_id: str = Form(...),
        mode: str = Form("practice")
):
    global database

    if database is None:
        if not await connect_to_mongodb():
            raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    if not whisper_model:
        raise HTTPException(status_code=500, detail="ìŒì„± ì¸ì‹ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    temp_audio_path = None   # ğŸ”¹ ë¯¸ë¦¬ ì„ ì–¸
    transcription = None     # ğŸ”¹ ë¯¸ë¦¬ ì„ ì–¸

    try:
        # ì§ˆë¬¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        question_doc = await database.questions.find_one({"_id": ObjectId(question_id)})
        if not question_doc:
            raise HTTPException(status_code=404, detail="ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ìŒì„± íŒŒì¼ ì„ì‹œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_audio:
            content = await audio.read()
            temp_audio.write(content)
            temp_audio_path = temp_audio.name

        # Whisperë¡œ ìŒì„± ë³€í™˜
        result = whisper_model.transcribe(temp_audio_path)
        transcription = result.get("text", "").strip()

        if not transcription:
            raise HTTPException(status_code=400, detail="ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # AI í‰ê°€
        evaluation = await evaluator.evaluate_response(
            question_doc["question_text"], transcription
        )

        response = {
            "question_id": question_id,
            "question_text": question_doc["question_text"],
            "transcription": transcription,
            "user_answer": transcription,
            "grade": evaluation["grade"],
            "score": evaluation["score"],
            "problem_understanding": evaluation["problem_understanding"],
            "answer_structure": evaluation["answer_structure"],
            "content_expression": evaluation["content_expression"],
            "topic_delivery": evaluation["topic_delivery"],
            "overall_feedback": evaluation["overall_feedback"],
            "mode": mode,
            "timestamp": datetime.now().isoformat()
        }

        if mode != "practice":
            await database.evaluations.insert_one(response)

        logger.info(f"ìŒì„± í‰ê°€ ì™„ë£Œ - ì ìˆ˜: {evaluation['score']}")
        return jsonable_encoder(response)  # ğŸ”¹ ì•ˆì „í•˜ê²Œ JSON ë³€í™˜

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìŒì„± í‰ê°€ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ìŒì„± í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    finally:
        if temp_audio_path and os.path.exists(temp_audio_path):
            try:
                os.unlink(temp_audio_path)
            except Exception as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")


@app.options("/evaluate-text")
async def options_evaluate_text():
    """CORS preflight ìš”ì²­ ì²˜ë¦¬"""
    return {"message": "OK"}


@app.post("/evaluate-text")
async def evaluate_text_response(submission: TextSubmission):
    """í…ìŠ¤íŠ¸ ë‹µë³€ í‰ê°€"""
    global database

    if database is None:
        if not await connect_to_mongodb():
            raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    try:
        # ì§ˆë¬¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        question_doc = await database.questions.find_one({"_id": ObjectId(submission.question_id)})
        if not question_doc:
            raise HTTPException(status_code=404, detail="ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # AI í‰ê°€
        evaluation = await evaluator.evaluate_response(question_doc["question_text"], submission.user_text)

        response = {
            "question_id": submission.question_id,
            "question_text": question_doc["question_text"],
            "user_answer": submission.user_text,
            "grade": evaluation["grade"],
            "score": evaluation["score"],
            "problem_understanding": evaluation["problem_understanding"],
            "answer_structure": evaluation["answer_structure"],
            "content_expression": evaluation["content_expression"],
            "topic_delivery": evaluation["topic_delivery"],
            "overall_feedback": evaluation["overall_feedback"],
            "mode": submission.mode,
            "timestamp": datetime.now().isoformat()
        }

        # ì—°ìŠµ ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš° ê²°ê³¼ ì €ì¥
        if submission.mode != "practice":
            await database.evaluations.insert_one(response)

        logger.info(f"í…ìŠ¤íŠ¸ í‰ê°€ ì™„ë£Œ - ì ìˆ˜: {evaluation['score']}")
        return response

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ í‰ê°€ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í…ìŠ¤íŠ¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.get("/exam-results/{session_id}")
async def get_exam_results(session_id: str):
    """ì‹œí—˜ ì„¸ì…˜ ê²°ê³¼ ì¡°íšŒ"""
    global database

    if not database:
        if not await connect_to_mongodb():
            raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    try:
        # ì„¸ì…˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        session = await database.exam_sessions.find_one({"_id": ObjectId(session_id)})
        if not session:
            raise HTTPException(status_code=404, detail="ì‹œí—˜ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # í•´ë‹¹ ì„¸ì…˜ì˜ í‰ê°€ ê²°ê³¼ë“¤ ê°€ì ¸ì˜¤ê¸°
        evaluations = await database.evaluations.find({
            "question_id": {"$in": session["questions"]}
        }).to_list(length=None)

        # í‰ê·  ì ìˆ˜ ê³„ì‚°
        if evaluations:
            avg_score = sum([eval["score"] for eval in evaluations]) / len(evaluations)
            avg_grade = sum([int(eval["grade"]) for eval in evaluations]) / len(evaluations)
        else:
            avg_score = 0
            avg_grade = 0

        return {
            "session_id": session_id,
            "topic": session["topic"],
            "total_questions": session["question_count"],
            "completed_questions": len(evaluations),
            "average_score": round(avg_score, 1),
            "average_grade": round(avg_grade, 1),
            "evaluations": evaluations,
            "created_at": session["created_at"]
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì‹œí—˜ ê²°ê³¼ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì‹œí—˜ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.get("/health")
async def health_check():
    try:
        # ì»¬ë ‰ì…˜ì—ì„œ ê°„ë‹¨í•œ ì‘ì—…ìœ¼ë¡œ ì—°ê²° í™•ì¸
        collection_names = await database.list_collection_names()

        return {
            "status": "healthy",
            "mongodb": {
                "status": "connected"
            }
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "mongodb": {
                "status": "error",
                "error": str(e)
            }
        }

    health_data = {
        "status": "healthy" if db_status == "connected" else "unhealthy",
        "whisper_model": "loaded" if whisper_model else "unavailable",
        "groq_api": "ready" if groq_client else "unavailable",
        "mongodb": {
            "status": db_status,
            "url": MONGODB_URL,
            "database": DATABASE_NAME
        },
        "timestamp": datetime.now().isoformat()
    }

    if db_error:
        health_data["mongodb"]["error"] = db_error

    return health_data


# ì¶”ê°€ ë””ë²„ê¹… ì—”ë“œí¬ì¸íŠ¸
@app.get("/debug/mongodb")
async def debug_mongodb():
    """MongoDB ì—°ê²° ë° ë°ì´í„° ìƒíƒœ ë””ë²„ê¹…"""
    global client, database

    debug_info = {
        "client_status": "connected" if client else "not_connected",
        "database_status": "available" if database else "not_available",
        "mongodb_url": MONGODB_URL,
        "database_name": DATABASE_NAME
    }

    try:
        if database is None:
            await connect_to_mongodb()

        if database is not None:
            # ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡
            db_list = await client.list_database_names()
            debug_info["available_databases"] = db_list

            # ì»¬ë ‰ì…˜ ëª©ë¡
            collections = await database.list_collection_names()
            debug_info["collections"] = collections

            # questions ì»¬ë ‰ì…˜ í†µê³„
            if "questions" in collections:
                count = await database.questions.count_documents({})
                debug_info["questions_count"] = count

                # ì£¼ì œë³„ í†µê³„
                pipeline = [
                    {"$group": {"_id": "$topic", "count": {"$sum": 1}}},
                    {"$sort": {"_id": 1}}
                ]
                topics = await database.questions.aggregate(pipeline).to_list(length=None)
                debug_info["topics"] = topics

                # ìƒ˜í”Œ ë¬¸ì„œ
                if count > 0:
                    sample = await database.questions.find_one()
                    debug_info["sample_question"] = {
                        "id": str(sample["_id"]),
                        "topic": sample.get("topic"),
                        "difficulty": sample.get("difficulty"),
                        "question_preview": sample.get("question_text", "")[:100] + "..."
                    }
            else:
                debug_info["questions_collection"] = "not_found"

    except Exception as e:
        debug_info["error"] = str(e)
        debug_info["error_type"] = type(e).__name__

    return debug_info


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "Opic_test:app",  # íŒŒì¼ëª…ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”
        host="0.0.0.0",
        port=8003,
        reload=True,
        log_level="info"
    )